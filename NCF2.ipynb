{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "mount_file_id": "1zrHfWUBmh7iGB2yi7zbSPtXVo45iEU17",
      "authorship_tag": "ABX9TyNLB/wHjUw2lljG+jMDxgV8",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/harishkumar1218/neural_collaborative_filtering_with_tensorflow/blob/main/NCF2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.layers import Embedding, Input, Dense, Flatten, Multiply,Concatenate\n",
        "from tensorflow.keras.optimizers.legacy import Adagrad, Adam, SGD, RMSprop\n",
        "from tensorflow.keras.initializers import RandomNormal\n",
        "from tensorflow.keras.regularizers import l2\n",
        "from tensorflow.keras.models import Model\n",
        "import scipy.sparse as sp\n",
        "import tensorflow as tf\n",
        "import multiprocessing\n",
        "from time import time\n",
        "import numpy as np\n",
        "import heapq\n",
        "import math"
      ],
      "metadata": {
        "id": "0Z-zglce78K1"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#GMF\n",
        "class GMF:\n",
        "  def init_normal(shape, name=None):\n",
        "      return tf.random_normal(shape, stddev=0.01)\n",
        "\n",
        "  def get_model(num_users, num_items, latent_dim, regs=[0, 0]):\n",
        "      # Input variables\n",
        "      user_input = Input(shape=(1,), dtype=tf.int32, name='user_input')\n",
        "      item_input = Input(shape=(1,), dtype=tf.int32, name='item_input')\n",
        "\n",
        "      MF_Embedding_User = Embedding(input_dim=num_users, output_dim=latent_dim, name='user_embedding',\n",
        "                                    embeddings_initializer=init_normal, embeddings_regularizer=l2(regs[0]), input_length=1)\n",
        "      MF_Embedding_Item = Embedding(input_dim=num_items, output_dim=latent_dim, name='item_embedding',\n",
        "                                    embeddings_initializer=init_normal, embeddings_regularizer=l2(regs[1]), input_length=1)\n",
        "\n",
        "      # Crucial to flatten an embedding vector!\n",
        "      user_latent = Flatten()(MF_Embedding_User(user_input))\n",
        "      item_latent = Flatten()(MF_Embedding_Item(item_input))\n",
        "\n",
        "      # Element-wise product of user and item embeddings\n",
        "      predict_vector = Multiply()([user_latent, item_latent])\n",
        "\n",
        "      # Final prediction layer\n",
        "      prediction = Dense(1, activation='sigmoid', kernel_initializer='lecun_uniform', name='prediction')(predict_vector)\n",
        "\n",
        "      model = Model(inputs=[user_input, item_input], outputs=prediction)\n",
        "\n",
        "      return model"
      ],
      "metadata": {
        "id": "WAvYy5YC3jg4"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#MLP\n",
        "class MLP:\n",
        "  def init_normal(shape):\n",
        "      return tf.random_normal(shape, stddev=0.01)\n",
        "\n",
        "  def get_model(num_users, num_items, layers=[64,32,16,8], reg_layers=[0,0,0,0]):\n",
        "      assert len(layers) == len(reg_layers)\n",
        "      num_layer = len(layers)\n",
        "      user_input = Input(shape=(1,), dtype=tf.int32, name='user_input')\n",
        "      item_input = Input(shape=(1,), dtype=tf.int32, name='item_input')\n",
        "\n",
        "      MLP_Embedding_User = Embedding(input_dim=num_users, output_dim=layers[0]//2, name='user_embedding',\n",
        "                                    embeddings_initializer=init_normal, embeddings_regularizer=l2(reg_layers[0]), input_length=1)\n",
        "      MLP_Embedding_Item = Embedding(input_dim=num_items, output_dim=layers[0]//2, name='item_embedding',\n",
        "                                    embeddings_initializer=init_normal, embeddings_regularizer=l2(reg_layers[0]), input_length=1)\n",
        "\n",
        "      user_latent = Flatten()(MLP_Embedding_User(user_input))\n",
        "      item_latent = Flatten()(MLP_Embedding_Item(item_input))\n",
        "\n",
        "      vector = Concatenate()([user_latent, item_latent])\n",
        "\n",
        "      for idx in range(1, num_layer):\n",
        "          layer = Dense(layers[idx], kernel_regularizer=l2(reg_layers[idx]), activation='relu', name='layer%d' %idx)\n",
        "          vector = layer(vector)\n",
        "\n",
        "      prediction = Dense(1, activation='sigmoid', kernel_initializer='lecun_uniform', name='prediction')(vector)\n",
        "\n",
        "      model = Model(inputs=[user_input, item_input], outputs=prediction)\n",
        "\n",
        "      return model\n"
      ],
      "metadata": {
        "id": "Q5cGyQqB4D8-"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Evaluation:\n",
        "    def __init__(self, model, testRatings, testNegatives, K):\n",
        "        self.model = model\n",
        "        self.testRatings = testRatings\n",
        "        self.testNegatives = testNegatives\n",
        "        self.K = K\n",
        "\n",
        "    def evaluate_model(self, num_thread):\n",
        "        hits, ndcgs = [], []\n",
        "        if num_thread > 1:  # Multi-thread\n",
        "            pool = multiprocessing.Pool(processes=num_thread)\n",
        "            res = pool.map(self.eval_one_rating, range(len(self.testRatings)))\n",
        "            pool.close()\n",
        "            pool.join()\n",
        "            hits = [r[0] for r in res]\n",
        "            ndcgs = [r[1] for r in res]\n",
        "            return hits, ndcgs\n",
        "        # Single thread\n",
        "        for idx in range(len(self.testRatings)):\n",
        "            (hr, ndcg) = self.eval_one_rating(idx)\n",
        "            hits.append(hr)\n",
        "            ndcgs.append(ndcg)\n",
        "        return hits, ndcgs\n",
        "\n",
        "    def eval_one_rating(self, idx):\n",
        "        rating = self.testRatings[idx]\n",
        "        items = self.testNegatives[idx]\n",
        "        u = rating[0]\n",
        "        gtItem = rating[1]\n",
        "        items.append(gtItem)\n",
        "        # Get prediction scores\n",
        "        map_item_score = {}\n",
        "        users = np.full(len(items), u, dtype='int32')\n",
        "        predictions = self.model.predict([users, np.array(items)],\n",
        "                                          batch_size=100, verbose=0)\n",
        "        for i in range(len(items)):\n",
        "            item = items[i]\n",
        "            map_item_score[item] = predictions[i]\n",
        "        items.pop()\n",
        "\n",
        "        # Evaluate top rank list\n",
        "        ranklist = heapq.nlargest(self.K, map_item_score, key=map_item_score.get)\n",
        "        hr = self.getHitRatio(ranklist, gtItem)\n",
        "        ndcg = self.getNDCG(ranklist, gtItem)\n",
        "        return hr, ndcg\n",
        "\n",
        "    @staticmethod\n",
        "    def getHitRatio(ranklist, gtItem):\n",
        "        for item in ranklist:\n",
        "            if item == gtItem:\n",
        "                return 1\n",
        "        return 0\n",
        "\n",
        "    @staticmethod\n",
        "    def getNDCG(ranklist, gtItem):\n",
        "        for i in range(len(ranklist)):\n",
        "            item = ranklist[i]\n",
        "            if item == gtItem:\n",
        "                return math.log(2) / math.log(i + 2)\n",
        "        return 0\n",
        "\n"
      ],
      "metadata": {
        "id": "xXuu4OP26K5D"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Dataset(object):\n",
        "    def __init__(self, path):\n",
        "        self.trainMatrix = self.load_rating_file_as_matrix(path + \".train.rating\")\n",
        "        self.testRatings = self.load_rating_file_as_list(path + \".test.rating\")\n",
        "        self.testNegatives = self.load_negative_file(path + \".test.negative\")\n",
        "        assert len(self.testRatings) == len(self.testNegatives)\n",
        "        self.num_users, self.num_items = self.trainMatrix.shape\n",
        "\n",
        "    def load_rating_file_as_list(self, filename):\n",
        "        ratingList = []\n",
        "        with open(filename, \"r\") as f:\n",
        "            line = f.readline()\n",
        "            while line != None and line != \"\":\n",
        "                arr = line.split(\"\\t\")\n",
        "                user, item = int(arr[0]), int(arr[1])\n",
        "                ratingList.append([user, item])\n",
        "                line = f.readline()\n",
        "        return ratingList\n",
        "\n",
        "    def load_negative_file(self, filename):\n",
        "        negativeList = []\n",
        "        with open(filename, \"r\") as f:\n",
        "            line = f.readline()\n",
        "            while line != None and line != \"\":\n",
        "                arr = line.split(\"\\t\")\n",
        "                negatives = []\n",
        "                for x in arr[1:]:\n",
        "                    negatives.append(int(x))\n",
        "                negativeList.append(negatives)\n",
        "                line = f.readline()\n",
        "        return negativeList\n",
        "\n",
        "    def load_rating_file_as_matrix(self, filename):\n",
        "        '''\n",
        "        Read .rating file and Return dok matrix.\n",
        "        The first line of .rating file is: num_users\\t num_items\n",
        "        '''\n",
        "        # Get number of users and items\n",
        "        num_users, num_items = 0, 0\n",
        "        with open(filename, \"r\") as f:\n",
        "            line = f.readline()\n",
        "            while line != None and line != \"\":\n",
        "                arr = line.split(\"\\t\")\n",
        "                u, i = int(arr[0]), int(arr[1])\n",
        "                num_users = max(num_users, u)\n",
        "                num_items = max(num_items, i)\n",
        "                line = f.readline()\n",
        "\n",
        "        # Construct matrix\n",
        "        mat = sp.dok_matrix((num_users+1, num_items+1), dtype=np.float32)\n",
        "        with open(filename, \"r\") as f:\n",
        "            line = f.readline()\n",
        "            while line != None and line != \"\":\n",
        "                arr = line.split(\"\\t\")\n",
        "                user, item, rating = int(arr[0]), int(arr[1]), float(arr[2])\n",
        "                if (rating > 0):\n",
        "                    mat[user, item] = 1.0\n",
        "                line = f.readline()\n",
        "        return mat\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "3lW1pcGh7vDx"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#NeuMF\n",
        "def get_model(num_users, num_items, mf_dim=10, layers=[10], reg_layers=[0], reg_mf=0):\n",
        "    assert len(layers) == len(reg_layers)\n",
        "    num_layer = len(layers) #Number of layers in the MLP\n",
        "\n",
        "    # Input variables\n",
        "    user_input = Input(shape=(1,), dtype=tf.int32, name='user_input')\n",
        "    item_input = Input(shape=(1,), dtype=tf.int32, name='item_input')\n",
        "\n",
        "    # Embedding layer\n",
        "    MF_Embedding_User = Embedding(input_dim=num_users, output_dim=mf_dim, name='mf_embedding_user',\n",
        "                                  embeddings_initializer=RandomNormal(mean=0.0, stddev=0.01),\n",
        "                                  embeddings_regularizer=l2(reg_mf), input_length=1)\n",
        "    MF_Embedding_Item = Embedding(input_dim=num_items, output_dim=mf_dim, name='mf_embedding_item',\n",
        "                                  embeddings_initializer=RandomNormal(mean=0.0, stddev=0.01),\n",
        "                                  embeddings_regularizer=l2(reg_mf), input_length=1)\n",
        "\n",
        "    MLP_Embedding_User = Embedding(input_dim=num_users, output_dim=layers[0]//2, name='mlp_embedding_user',\n",
        "                                   embeddings_initializer=RandomNormal(mean=0.0, stddev=0.01),\n",
        "                                   embeddings_regularizer=l2(reg_layers[0]), input_length=1)\n",
        "    MLP_Embedding_Item = Embedding(input_dim=num_items, output_dim=layers[0]//2, name='mlp_embedding_item',\n",
        "                                   embeddings_initializer=RandomNormal(mean=0.0, stddev=0.01),\n",
        "                                   embeddings_regularizer=l2(reg_layers[0]), input_length=1)\n",
        "\n",
        "    # MF part\n",
        "    mf_user_latent = Flatten()(MF_Embedding_User(user_input))\n",
        "    mf_item_latent = Flatten()(MF_Embedding_Item(item_input))\n",
        "    mf_vector = Multiply()([mf_user_latent, mf_item_latent]) # element-wise multiply\n",
        "\n",
        "    # MLP part\n",
        "    mlp_user_latent = Flatten()(MLP_Embedding_User(user_input))\n",
        "    mlp_item_latent = Flatten()(MLP_Embedding_Item(item_input))\n",
        "    mlp_vector = Concatenate()([mlp_user_latent, mlp_item_latent])\n",
        "    for idx in range(1, num_layer):\n",
        "        layer = Dense(layers[idx], kernel_regularizer=l2(reg_layers[idx]), activation='relu', name=\"layer%d\" %idx)\n",
        "        mlp_vector = layer(mlp_vector)\n",
        "\n",
        "    # Concatenate MF and MLP parts\n",
        "    predict_vector = Concatenate()([mf_vector, mlp_vector])\n",
        "\n",
        "    # Final prediction layer\n",
        "    prediction = Dense(1, activation='sigmoid', kernel_initializer='lecun_uniform', name=\"prediction\")(predict_vector)\n",
        "\n",
        "    model = Model(inputs=[user_input, item_input], outputs=prediction)\n",
        "\n",
        "    return model\n",
        "\n",
        "def load_pretrain_model(model, gmf_model, mlp_model, num_layers):\n",
        "    # MF embeddings\n",
        "    gmf_user_embeddings = gmf_model.get_layer('user_embedding').get_weights()\n",
        "    gmf_item_embeddings = gmf_model.get_layer('item_embedding').get_weights()\n",
        "    model.get_layer('mf_embedding_user').set_weights(gmf_user_embeddings)\n",
        "    model.get_layer('mf_embedding_item').set_weights(gmf_item_embeddings)\n",
        "\n",
        "    # MLP embeddings\n",
        "    mlp_user_embeddings = mlp_model.get_layer('user_embedding').get_weights()\n",
        "    mlp_item_embeddings = mlp_model.get_layer('item_embedding').get_weights()\n",
        "    model.get_layer('mlp_embedding_user').set_weights(mlp_user_embeddings)\n",
        "    model.get_layer('mlp_embedding_item').set_weights(mlp_item_embeddings)\n",
        "\n",
        "    # MLP layers\n",
        "    for i in range(1, num_layers):\n",
        "        mlp_layer_weights = mlp_model.get_layer('layer%d' %i).get_weights()\n",
        "        model.get_layer('layer%d' %i).set_weights(mlp_layer_weights)\n",
        "\n",
        "    # Prediction weights\n",
        "    gmf_prediction = gmf_model.get_layer('prediction').get_weights()\n",
        "    mlp_prediction = mlp_model.get_layer('prediction').get_weights()\n",
        "    new_weights = np.concatenate((gmf_prediction[0], mlp_prediction[0]), axis=0)\n",
        "    new_b = gmf_prediction[1] + mlp_prediction[1]\n",
        "    model.get_layer('prediction').set_weights([0.5*new_weights, 0.5*new_b])\n",
        "    return model\n",
        "\n",
        "def get_train_instances(train, num_negatives):\n",
        "    user_input, item_input, labels = [],[],[]\n",
        "    num_users = train.shape[0]\n",
        "    for (u, i) in train.keys():\n",
        "        # positive instance\n",
        "        user_input.append(u)\n",
        "        item_input.append(i)\n",
        "        labels.append(1)\n",
        "        # negative instances\n",
        "        for t in range(num_negatives):\n",
        "            j = np.random.randint(num_items)\n",
        "            while (u, j)in train:\n",
        "                j = np.random.randint(num_items)\n",
        "            user_input.append(u)\n",
        "            item_input.append(j)\n",
        "            labels.append(0)\n",
        "    return user_input, item_input, labels\n"
      ],
      "metadata": {
        "id": "_MInd-CvFif5"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#python NeuMF.py --dataset ml-1m --epochs 20 --batch_size 256 --num_factors 8 --layers [64,32,16,8] --reg_mf 0 --reg_layers [0,0,0,0] --num_neg 4 --lr 0.001 --learner adam --verbose 1 --out 1\n",
        "num_epochs = 5\n",
        "batch_size = 256\n",
        "mf_dim = 8\n",
        "layers = [64,32,16,8]\n",
        "reg_mf = 0\n",
        "reg_layers = [0,0,0,0]\n",
        "num_negatives = 4\n",
        "learning_rate = 0.001\n",
        "learner = \"adam\"\n",
        "verbose = 1\n",
        "mf_pretrain = ''\n",
        "mlp_pretrain = ''\n",
        "save_model=1\n",
        "topK = 10\n",
        "evaluation_threads = 3 #mp.cpu_count()\n",
        "model_out_file = f'/content/sample_data/model{time()}.h5'\n"
      ],
      "metadata": {
        "id": "9KRJYfJJF3yL"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Loading data\n",
        "t1 = time()\n",
        "dataset = Dataset(\"/content/drive/MyDrive/neural_collaborative_filtering-master/Data/ml-1m\")\n",
        "train, testRatings, testNegatives = dataset.trainMatrix, dataset.testRatings, dataset.testNegatives\n",
        "num_users, num_items = train.shape\n",
        "print(\"Load data done [%.1f s]. #user=%d, #item=%d, #train=%d, #test=%d\"\n",
        "      %(time()-t1, num_users, num_items, train.nnz, len(testRatings)))\n",
        "\n",
        "# Build model\n",
        "model = get_model(num_users, num_items, mf_dim, layers, reg_layers, reg_mf)\n",
        "if learner.lower() == \"adagrad\":\n",
        "    model.compile(optimizer=Adagrad(lr=learning_rate), loss='binary_crossentropy')\n",
        "elif learner.lower() == \"rmsprop\":\n",
        "    model.compile(optimizer=RMSprop(lr=learning_rate), loss='binary_crossentropy')\n",
        "elif learner.lower() == \"adam\":\n",
        "    model.compile(optimizer=Adam(lr=learning_rate), loss='binary_crossentropy')\n",
        "else:\n",
        "    model.compile(optimizer=SGD(lr=learning_rate), loss='binary_crossentropy')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lKCI0bSPK7wD",
        "outputId": "d8cbaba2-3204-4110-99a2-098acc2efde2"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Load data done [16.9 s]. #user=6040, #item=3706, #train=994169, #test=6040\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/optimizers/legacy/adam.py:118: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super().__init__(name, **kwargs)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load pretrain model\n",
        "if mf_pretrain != '' and mlp_pretrain != '':\n",
        "    gmf_model = GMF.get_model(num_users,num_items,mf_dim)\n",
        "    gmf_model.load_weights(mf_pretrain)\n",
        "    mlp_model = MLP.get_model(num_users,num_items, layers, reg_layers)\n",
        "    mlp_model.load_weights(mlp_pretrain)\n",
        "    model = load_pretrain_model(model, gmf_model, mlp_model, len(layers))\n",
        "    print(f'Load pretrained GMF {mf_pretrain} and MLP {mlp_pretrain} models done.' )"
      ],
      "metadata": {
        "id": "07y9afihLTic"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Init performance\n",
        "(hits, ndcgs) = Evaluation(model, testRatings, testNegatives, topK).evaluate_model(evaluation_threads)\n",
        "hr, ndcg = np.array(hits).mean(), np.array(ndcgs).mean()\n",
        "print('Init: HR = %.4f, NDCG = %.4f' % (hr, ndcg))\n",
        "best_hr, best_ndcg, best_iter = hr, ndcg, -1\n",
        "if save_model > 0:\n",
        "    model.save_weights(model_out_file, overwrite=True)"
      ],
      "metadata": {
        "id": "PRhA73mULXXK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mAANcD5C3UNd",
        "outputId": "a56f15bf-95e1-4f7f-e986-797dad2a12ba"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iteration 0 [163.6 s]: HR = 0.5975, NDCG = 0.3409, loss = 0.3165 [534.9 s]\n",
            "Iteration 1 [116.2 s]: HR = 0.6354, NDCG = 0.3707, loss = 0.2718 [557.1 s]\n",
            "Iteration 2 [164.6 s]: HR = 0.6490, NDCG = 0.3811, loss = 0.2625 [565.1 s]\n",
            "Iteration 3 [162.7 s]: HR = 0.6603, NDCG = 0.3877, loss = 0.2577 [576.6 s]\n",
            "Iteration 4 [117.5 s]: HR = 0.6639, NDCG = 0.3941, loss = 0.2542 [572.5 s]\n",
            "End. Best Iteration 4:  HR = 0.6639, NDCG = 0.3941. \n",
            "The best NeuMF model is saved to /content/sample_data/model1711217973.1932163.h5\n"
          ]
        }
      ],
      "source": [
        "# Training model\n",
        "for epoch in range(num_epochs):\n",
        "    t1 = time()\n",
        "    # Generate training instances\n",
        "    user_input, item_input, labels = get_train_instances(train, num_negatives)\n",
        "\n",
        "    # Training\n",
        "    hist = model.fit([np.array(user_input), np.array(item_input)], #input\n",
        "                      np.array(labels), # labels\n",
        "                      batch_size=batch_size, verbose=0, shuffle=True,epochs=1)\n",
        "    t2 = time()\n",
        "\n",
        "    # Evaluation\n",
        "    if epoch %verbose == 0:\n",
        "        (hits, ndcgs) =Evaluation(model, testRatings, testNegatives, topK).evaluate_model(evaluation_threads)\n",
        "        hr, ndcg, loss = np.array(hits).mean(), np.array(ndcgs).mean(), hist.history['loss'][0]\n",
        "        print('Iteration %d [%.1f s]: HR = %.4f, NDCG = %.4f, loss = %.4f [%.1f s]'\n",
        "              % (epoch,  t2-t1, hr, ndcg, loss, time()-t2))\n",
        "        if hr > best_hr:\n",
        "            best_hr, best_ndcg, best_iter = hr, ndcg, epoch\n",
        "            if save_model > 0:\n",
        "                model.save_weights(model_out_file, overwrite=True)\n",
        "\n",
        "print(\"End. Best Iteration %d:  HR = %.4f, NDCG = %.4f. \" %(best_iter, best_hr, best_ndcg))\n",
        "if save_model > 0:\n",
        "    print(\"The best NeuMF model is saved to %s\" %(model_out_file))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "# Load the model\n",
        "model = get_model(num_users, num_items, mf_dim, layers, reg_layers, reg_mf)\n",
        "model.load_weights(\"/content/sample_data/model17112179731932163.h5\")\n",
        "\n",
        "\n",
        "# Prepare input data for prediction (replace this with your actual input data)\n",
        "# input_data = \"\"\n",
        "\n",
        "# # Make predictions\n",
        "predictions = model.predict([np.array([22]),np.array([934])])\n",
        "\n",
        "\n",
        "\n",
        "print(predictions[0][0]*100)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4Meyc-lT01km",
        "outputId": "fac3c097-7203-49fe-e5ab-7899134fb91b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 124ms/step\n",
            "20.198437571525574\n"
          ]
        }
      ]
    }
  ]
}